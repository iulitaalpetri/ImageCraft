{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":234911,"sourceType":"datasetVersion","datasetId":99505},{"sourceId":8598647,"sourceType":"datasetVersion","datasetId":5144267}],"dockerImageVersionId":18199,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# display some images for every different expression\n\nimport numpy as np\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img, img_to_array\nimport matplotlib.pyplot as plt\nimport os\n\n# size of the image: 48*48 pixels\npic_size = 48\n\n# input path for the images\nbase_path = \"../input/images/images/\"\n\nplt.figure(0, figsize=(12,20))\ncpt = 0\n\nfor expression in os.listdir(base_path + \"train/\"):\n    for i in range(1,6):\n        cpt = cpt + 1\n        plt.subplot(7,5,cpt)\n        img = load_img(base_path + \"train/\" + expression + \"/\" +os.listdir(base_path + \"train/\" + expression)[i], target_size=(pic_size, pic_size))\n        plt.imshow(img, cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"ada86668a25cba36e2676a20bc76f96581057d26","execution":{"iopub.status.busy":"2024-06-03T22:32:53.160320Z","iopub.execute_input":"2024-06-03T22:32:53.160674Z","iopub.status.idle":"2024-06-03T22:32:59.088746Z","shell.execute_reply.started":"2024-06-03T22:32:53.160619Z","shell.execute_reply":"2024-06-03T22:32:59.088130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"bcedb42d1126f4692f3aa09434eb35e5f7d1b3d6"}},{"cell_type":"code","source":"# count number of train images for each expression\n\nfor expression in os.listdir(base_path + \"train\"):\n    print(str(len(os.listdir(base_path + \"train/\" + expression))) + \" \" + expression + \" images\")","metadata":{"_uuid":"2fc206564d516020e9c3001c8a1448766aace848","execution":{"iopub.status.busy":"2024-06-03T22:33:05.219218Z","iopub.execute_input":"2024-06-03T22:33:05.219504Z","iopub.status.idle":"2024-06-03T22:33:05.244119Z","shell.execute_reply.started":"2024-06-03T22:33:05.219460Z","shell.execute_reply":"2024-06-03T22:33:05.243308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The image expressions in our training dataset are pretty balanced, except for the 'disgust' category.","metadata":{"_uuid":"a685f736404cffdf2076bd9b941b8b170c3fa23d","trusted":true}},{"cell_type":"markdown","source":"# Setup the data generators","metadata":{"_uuid":"74f292f501e5a60adb5463f412f42e5584f3a6a5","trusted":true}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n# number of images to feed into the NN for every batch\nbatch_size = 128\n\ndatagen_train = ImageDataGenerator(\n    rotation_range=20,  # Rotiri aleatorii între 0 și 20 de grade\n    horizontal_flip=True,  # Reflectare orizontală (util pentru majoritatea task-urilor, dar nu pentru text/scris)\n    fill_mode='nearest',  # Modul de umplere a pixelilor noi care pot apărea după rotire sau lărgire\n)\n\ndatagen_validation = ImageDataGenerator()\n\ntrain_generator = datagen_train.flow_from_directory(base_path + \"train\",\n                                                    target_size=(pic_size,pic_size),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=True)\n\nvalidation_generator = datagen_validation.flow_from_directory(base_path + \"validation\",\n                                                    target_size=(pic_size,pic_size),\n                                                    color_mode=\"grayscale\",\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    shuffle=False)\n\n\n\n\n\n","metadata":{"_uuid":"0041128a27f4da936ad63e90959797391736fc8b","execution":{"iopub.status.busy":"2024-06-03T22:33:09.443487Z","iopub.execute_input":"2024-06-03T22:33:09.443771Z","iopub.status.idle":"2024-06-03T22:33:24.496057Z","shell.execute_reply.started":"2024-06-03T22:33:09.443727Z","shell.execute_reply":"2024-06-03T22:33:24.495140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\n\n# number of possible label values\nnb_classes = 7\n\n# Initialising the CNN\nmodel = Sequential()\n\n# 1 - Convolution\nmodel.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(128,(5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(nb_classes, activation='softmax'))\n\nmodel.summary()\n\nopt = Adam(lr=0.0001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"_uuid":"4914afe556e0db3c03614ed1ac2138fd68d03815","execution":{"iopub.status.busy":"2024-06-03T22:33:43.235726Z","iopub.execute_input":"2024-06-03T22:33:43.236099Z","iopub.status.idle":"2024-06-03T22:33:45.872248Z","shell.execute_reply.started":"2024-06-03T22:33:43.236036Z","shell.execute_reply":"2024-06-03T22:33:45.871495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n\nclasses = 3205*[0]+ 4103*[1]+ 3993*[2]+ 4982*[3]+ 4938*[4]+ 436*[5]+ 7164*[6]\n\nweights = compute_class_weight('balanced', classes=np.unique(classes), y=classes)\nclass_weights = dict(enumerate(weights))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T23:02:45.417720Z","iopub.execute_input":"2024-06-03T23:02:45.418017Z","iopub.status.idle":"2024-06-03T23:02:45.441266Z","shell.execute_reply.started":"2024-06-03T23:02:45.417975Z","shell.execute_reply":"2024-06-03T23:02:45.440508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"a59f0528c8c3226cfb82d9564fbc27561e6d78ed","trusted":true}},{"cell_type":"markdown","source":"# Train the model","metadata":{"_uuid":"883ca4ab4d9c00ac08434916e7713c8f9b4353ba","trusted":true}},{"cell_type":"markdown","source":"Everything is set up, let's train our model now!","metadata":{"_uuid":"e5d128b83c8d2182f6112287776ce7f37c63936d"}},{"cell_type":"code","source":"%%time\n\n# number of epochs to train the NN\nepochs = 50\n\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit_generator(generator=train_generator,\n                                steps_per_epoch=train_generator.n//train_generator.batch_size,\n                                epochs=epochs,\n                                validation_data = validation_generator,\n                                validation_steps = validation_generator.n//validation_generator.batch_size,\n\n                                callbacks=callbacks_list\n                                )","metadata":{"_uuid":"8d3db222ae6b74ab55df0d840d372b4306af6db0","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"2e9eadc450fe57d829f8acb4d40a810b9367c08b"}},{"cell_type":"code","source":"# serialize model structure to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"_uuid":"2f2521fa426a3e4d7c9d4895b1b53e0fefcb7ff5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyze the results","metadata":{"_uuid":"3b1544cf2a38f9967dd357ed94ad4a59b9a86191","trusted":true}},{"cell_type":"markdown","source":"","metadata":{"_uuid":"571a5de1f9ca4a5648de2c085a67afce0e784531"}},{"cell_type":"code","source":"# plot the evolution of Loss and Acuracy on the train and validation sets\n\nimport matplotlib.pyplot as plt\n\n# plt.figure(figsize=(20,10))\n# plt.subplot(1, 2, 1)\n# plt.suptitle('Optimizer : Adam', fontsize=10)\n# plt.ylabel('Loss', fontsize=16)\n# plt.plot(history.history['loss'], label='Training Loss')\n# plt.plot(history.history['val_loss'], label='Validation Loss')\n# plt.legend(loc='upper right')\n\n# plt.subplot(1, 2, 2)\n# plt.ylabel('Accuracy', fontsize=16)\n# plt.plot(history.history['acc'], label='Training Accuracy')\n# plt.plot(history.history['val_acc'], label='Validation Accuracy')\n# plt.legend(loc='lower right')\n# plt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(121)\nplt.plot(history.history['loss'], 'b', label='Train Loss')\nplt.plot(history.history['val_loss'], 'r', label='Val Loss')\nplt.title('Loss')\nplt.legend()\n    \n\nplt.subplot(122)\nplt.plot(history.history['acc'], 'b', label='Train Accuracy')\nplt.plot(history.history['val_acc'], 'r', label='Val Accuracy')\n\nplt.title('Accuracy')\nplt.legend()\n    \nplt.figure(figsize=(20,10))","metadata":{"_uuid":"afa554be42c812c41438a89126e26eb459c3dd74","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"25e7825e2fd5cbff9cac17a577ff2925d476584d"}},{"cell_type":"code","source":"# show the confusion matrix of our predictions\n\n# compute predictions\npredictions = model.predict_generator(generator=validation_generator)\ny_pred = [np.argmax(probas) for probas in predictions]\ny_test = validation_generator.classes\nclass_names = validation_generator.class_indices.keys()\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n# compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\nplt.show()","metadata":{"_uuid":"4d2a670697c28add1f73f5d41c129c2df974f7b0","trusted":true},"execution_count":null,"outputs":[]}]}